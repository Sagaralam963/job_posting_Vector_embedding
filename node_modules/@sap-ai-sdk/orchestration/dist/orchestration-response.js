/**
 * Representation of an orchestration response.
 */
export class OrchestrationResponse {
    rawResponse;
    /**
     * The completion post response.
     */
    _data;
    constructor(rawResponse) {
        this.rawResponse = rawResponse;
        this._data = rawResponse.data;
    }
    /**
     * Usage of tokens in the response.
     * @returns Token usage.
     */
    getTokenUsage() {
        return this._data.final_result.usage;
    }
    /**
     * Reason for stopping the completion.
     * @param choiceIndex - The index of the choice to parse.
     * @returns The finish reason.
     */
    getFinishReason(choiceIndex = 0) {
        return this.findChoiceByIndex(choiceIndex)?.finish_reason;
    }
    /**
     * Parses the orchestration response and returns the content.
     * If the response was filtered, an error is thrown.
     * @param choiceIndex - The index of the choice to parse.
     * @returns The message content.
     */
    getContent(choiceIndex = 0) {
        const choice = this.findChoiceByIndex(choiceIndex);
        if (choice?.message?.content === '' &&
            choice?.finish_reason === 'content_filter') {
            throw new Error('Content generated by the LLM was filtered by the output filter. Please try again with a different prompt or filter configuration.');
        }
        return choice?.message?.content;
    }
    /**
     * Parses the orchestration response and returns the tool calls generated by the model.
     * @param choiceIndex - The index of the choice to parse.
     * @returns The message tool calls.
     */
    getToolCalls(choiceIndex = 0) {
        const choice = this.findChoiceByIndex(choiceIndex);
        return choice?.message?.tool_calls;
    }
    /**
     * Parses the orchestration response and returns the refusal message generated by the model.
     * @param choiceIndex - The index of the choice to parse.
     * @returns The refusal string.
     */
    getRefusal(choiceIndex = 0) {
        const choice = this.findChoiceByIndex(choiceIndex);
        return choice?.message?.refusal;
    }
    /**
     * Messages that can be used for subsequent prompts as message history.
     * @param choiceIndex - The index of the choice to parse.
     * @returns A list of all messages.
     */
    getAllMessages(choiceIndex = 0) {
        const messages = this._data.intermediate_results.templating ?? [];
        const content = this.findChoiceByIndex(choiceIndex)?.message;
        return content ? [...messages, content] : messages;
    }
    /**
     * Gets the assistant message from the response.
     * @param choiceIndex - The index of the choice to use (default is 0).
     * @returns The assistant message.
     */
    getAssistantMessage(choiceIndex = 0) {
        return this.findChoiceByIndex(choiceIndex)?.message;
    }
    /**
     * Gets the intermediate results from the orchestration response.
     * @returns The intermediate results.
     */
    getIntermediateResults() {
        return this._data.intermediate_results;
    }
    /**
     * Parses the response and returns the choice by index.
     * @param index - The index of the choice to find.
     * @returns An {@link LLMChoice} object associated with the index.
     */
    findChoiceByIndex(index) {
        return this.getChoices().find((c) => c.index === index);
    }
    getChoices() {
        return this._data.final_result.choices;
    }
}
//# sourceMappingURL=orchestration-response.js.map